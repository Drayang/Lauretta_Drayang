{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc24d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchreid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30d5f1",
   "metadata": {},
   "source": [
    "## Image dataset - market1501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4d58c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ random crop (enlarge to 288x144 and crop 256x128)\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded Market1501\n",
      "  ----------------------------------------\n",
      "  subset   | # ids | # images | # cameras\n",
      "  ----------------------------------------\n",
      "  train    |   751 |    12936 |         6\n",
      "  query    |   750 |     3368 |         6\n",
      "  gallery  |   751 |    15913 |         6\n",
      "  ----------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source            : ['market1501']\n",
      "  # source datasets : 1\n",
      "  # source ids      : 751\n",
      "  # source images   : 12936\n",
      "  # source cameras  : 6\n",
      "  target            : ['market1501']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "height=256\n",
    "width = 128\n",
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root=\"reid-data\",\n",
    "    sources=\"market1501\",\n",
    "    targets=\"market1501\",\n",
    "    height=height,\n",
    "    width=width,\n",
    "    batch_size_train=32,\n",
    "    batch_size_test=100,\n",
    "    transforms=[\"random_flip\", \"random_crop\"]\n",
    ")\n",
    "\n",
    "# return train loader of source data\n",
    "train_loader = datamanager.train_loader\n",
    "\n",
    "# return test loader of target data\n",
    "test_loader = datamanager.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55c33f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid import metrics\n",
    "\n",
    "# Returns query and gallery of a test dataset, each containing tuples of (img_path(s), pid, camid)\n",
    "dataset = datamanager.fetch_test_loaders(\"market1501\")\n",
    "data_type = \"image\"\n",
    "sav_dir = \"/output\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b0760",
   "metadata": {},
   "source": [
    "### Define hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcac1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"C:\\Users\\Drayang/.cache\\torch\\checkpoints\\osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"log/osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load model\n",
    "Use `torchreid.models.show_avai_models()` to check available model\n",
    "''' \n",
    "torchreid.models.show_avai_models()\n",
    "\n",
    "#create model\n",
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "# load pretrained weight to the model\n",
    "weight_path = 'log/osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth'\n",
    "torchreid.utils.load_pretrained_weights(model, weight_path)\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15282d74",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "762b7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5b4c1",
   "metadata": {},
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f4c2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating market1501 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 3368-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 15913-by-512 matrix\n",
      "Speed: 0.0338 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 82.6%\n",
      "CMC curve\n",
      "Rank-1  : 94.3%\n",
      "Rank-5  : 97.9%\n",
      "Rank-10 : 98.6%\n",
      "Rank-20 : 99.2%\n",
      "# query: 3368\n",
      "# gallery 15913\n",
      "Visualizing top-5 ranks ...\n",
      "- done 100/3368\n",
      "- done 200/3368\n",
      "- done 300/3368\n",
      "- done 400/3368\n",
      "- done 500/3368\n",
      "- done 600/3368\n",
      "- done 700/3368\n",
      "- done 800/3368\n",
      "- done 900/3368\n",
      "- done 1000/3368\n",
      "- done 1100/3368\n",
      "- done 1200/3368\n",
      "- done 1300/3368\n",
      "- done 1400/3368\n",
      "- done 1500/3368\n",
      "- done 1600/3368\n",
      "- done 1700/3368\n",
      "- done 1800/3368\n",
      "- done 1900/3368\n",
      "- done 2000/3368\n",
      "- done 2100/3368\n",
      "- done 2200/3368\n",
      "- done 2300/3368\n",
      "- done 2400/3368\n",
      "- done 2500/3368\n",
      "- done 2600/3368\n",
      "- done 2700/3368\n",
      "- done 2800/3368\n",
      "- done 2900/3368\n",
      "- done 3000/3368\n",
      "- done 3100/3368\n",
      "- done 3200/3368\n",
      "- done 3300/3368\n",
      "Done. Images have been saved to \"log/osnet_x1_0\\visrank_market1501\" ...\n"
     ]
    }
   ],
   "source": [
    "engine.run(\n",
    "    save_dir=\"log/osnet_x1_0\",\n",
    "    max_epoch=60,\n",
    "    eval_freq=10,\n",
    "    print_freq=10,\n",
    "    test_only=True,\n",
    "    visrank = True, # visualize rank result\n",
    "    visrank_topk = 5 # image to save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c79715",
   "metadata": {},
   "source": [
    "## Video Dataset - prid-2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b117f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded PRID2011\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    89 |         178 |         2\n",
      "  query    |    89 |          89 |         1\n",
      "  gallery  |    89 |          89 |         1\n",
      "  -------------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded PRID2011\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |    89 |         178 |         2\n",
      "  query    |    89 |          89 |         1\n",
      "  gallery  |    89 |          89 |         1\n",
      "  -------------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source             : ['prid2011']\n",
      "  # source datasets  : 1\n",
      "  # source ids       : 89\n",
      "  # source tracklets : 178\n",
      "  # source cameras   : 2\n",
      "  target             : ['prid2011']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='reid-data',\n",
    "    sources='prid2011',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=3,\n",
    "    batch_size_test=3,\n",
    "    seq_len=15,\n",
    "    sample_method='evenly'\n",
    ")\n",
    "\n",
    "# return train loader of source data\n",
    "train_loader = datamanager.train_loader\n",
    "\n",
    "# return test loader of target data\n",
    "test_loader = datamanager.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e56cb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"C:\\Users\\Drayang/.cache\\torch\\checkpoints\\osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"log/osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create model\n",
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "# load pretrained weight to the model\n",
    "weight_path = 'log/osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth'\n",
    "torchreid.utils.load_pretrained_weights(model, weight_path)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ce65fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmpile model\n",
    "engine = torchreid.engine.VideoSoftmaxEngine(\n",
    "    datamanager, model, optimizer, scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d18e8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating prid2011 (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 89-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 89-by-512 matrix\n",
      "Speed: 0.0315 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 42.2%\n",
      "CMC curve\n",
      "Rank-1  : 30.3%\n",
      "Rank-5  : 52.8%\n",
      "Rank-10 : 60.7%\n",
      "Rank-20 : 78.7%\n"
     ]
    }
   ],
   "source": [
    "engine.run(\n",
    "    max_epoch=60,\n",
    "    save_dir='log/oxnet_prid2011',\n",
    "    print_freq=10,\n",
    "    test_only=True,\n",
    "#     visrank = True, # visualize rank result\n",
    "#     visrank_topk = 5 # image to save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feb3e13",
   "metadata": {},
   "source": [
    "## Video dataset - dukemtmc-vidreid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "838d990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Generating split json file (** this might take a while **)\n",
      "Processing \"C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\DukeMTMC-VideoReID/train\" with 702 person identities\n",
      "Saving split to C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\split_train.json\n",
      "=> Generating split json file (** this might take a while **)\n",
      "Processing \"C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\DukeMTMC-VideoReID/query\" with 702 person identities\n",
      "Saving split to C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\split_query.json\n",
      "=> Generating split json file (** this might take a while **)\n",
      "Processing \"C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\DukeMTMC-VideoReID/gallery\" with 1110 person identities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Drayang\\GitHub\\deep-person-reid\\torchreid\\data\\datasets\\video\\dukemtmcvidreid.py:107: UserWarning: Index name F0001 in C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\DukeMTMC-VideoReID/gallery\\0002\\2197 is missing, skip\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving split to C:\\Users\\Drayang\\GitHub\\deep-person-reid\\reid-data\\dukemtmc-vidreid\\split_gallery.json\n",
      "=> Loaded DukeMTMCVidReID\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   702 |        2196 |         8\n",
      "  query    |   702 |         702 |         8\n",
      "  gallery  |  1110 |        2636 |         8\n",
      "  -------------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded DukeMTMCVidReID\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   702 |        2196 |         8\n",
      "  query    |   702 |         702 |         8\n",
      "  gallery  |  1110 |        2636 |         8\n",
      "  -------------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source             : ['dukemtmcvidreid']\n",
      "  # source datasets  : 1\n",
      "  # source ids       : 702\n",
      "  # source tracklets : 2196\n",
      "  # source cameras   : 8\n",
      "  target             : ['dukemtmcvidreid']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='reid-data',\n",
    "    sources='dukemtmcvidreid',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=10,\n",
    "    batch_size_test=10,\n",
    "    seq_len=15,\n",
    "    sample_method='evenly'\n",
    ")\n",
    "\n",
    "# return train loader of source data\n",
    "train_loader = datamanager.train_loader\n",
    "\n",
    "# return test loader of target data\n",
    "test_loader = datamanager.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "083436ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"C:\\Users\\Drayang/.cache\\torch\\checkpoints\\osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Successfully loaded pretrained weights from \"log/osnet_x1_0_duke_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth\"\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_x1_0\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "# load pretrained weight to the model\n",
    "weight_path = 'log/osnet_x1_0_duke_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth'\n",
    "torchreid.utils.load_pretrained_weights(model, weight_path)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0e233d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating dukemtmcvidreid (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 702-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 2636-by-512 matrix\n",
      "Speed: 0.0347 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 91.1%\n",
      "CMC curve\n",
      "Rank-1  : 92.6%\n",
      "Rank-5  : 98.6%\n",
      "Rank-10 : 99.1%\n",
      "Rank-20 : 99.4%\n"
     ]
    }
   ],
   "source": [
    "# COmpile model\n",
    "engine = torchreid.engine.VideoSoftmaxEngine(\n",
    "    datamanager, model, optimizer, scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\n",
    "\n",
    "engine.run(\n",
    "    max_epoch=20,\n",
    "    save_dir='log/oxnet_ilidsvid',\n",
    "    print_freq=10,\n",
    "    test_only=True,\n",
    "#     visrank = True, # visualize rank result\n",
    "#     visrank_topk = 5 # image to save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f8fd8",
   "metadata": {},
   "source": [
    "## Video Dataset- iLDS-VID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42297dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train transforms ...\n",
      "+ resize to 256x128\n",
      "+ random flip\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "Building test transforms ...\n",
      "+ resize to 256x128\n",
      "+ to torch tensor of range [0, 1]\n",
      "+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "=> Loading train (source) dataset\n",
      "=> Loaded iLIDSVID\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   150 |         300 |         2\n",
      "  query    |   150 |         150 |         1\n",
      "  gallery  |   150 |         150 |         1\n",
      "  -------------------------------------------\n",
      "=> Loading test (target) dataset\n",
      "=> Loaded iLIDSVID\n",
      "  -------------------------------------------\n",
      "  subset   | # ids | # tracklets | # cameras\n",
      "  -------------------------------------------\n",
      "  train    |   150 |         300 |         2\n",
      "  query    |   150 |         150 |         1\n",
      "  gallery  |   150 |         150 |         1\n",
      "  -------------------------------------------\n",
      "\n",
      "\n",
      "  **************** Summary ****************\n",
      "  source             : ['ilidsvid']\n",
      "  # source datasets  : 1\n",
      "  # source ids       : 150\n",
      "  # source tracklets : 300\n",
      "  # source cameras   : 2\n",
      "  target             : ['ilidsvid']\n",
      "  *****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datamanager = torchreid.data.VideoDataManager(\n",
    "    root='reid-data',\n",
    "    sources='ilidsvid',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=3,\n",
    "    batch_size_test=3,\n",
    "    seq_len=15,\n",
    "    sample_method='evenly'\n",
    ")\n",
    "\n",
    "# return train loader of source data\n",
    "train_loader = datamanager.train_loader\n",
    "\n",
    "# return test loader of target data\n",
    "test_loader = datamanager.test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0e3bf",
   "metadata": {},
   "source": [
    "### using the same model and hyperparameter as previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e94d5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Evaluating ilidsvid (source) #####\n",
      "Extracting features from query set ...\n",
      "Done, obtained 150-by-512 matrix\n",
      "Extracting features from gallery set ...\n",
      "Done, obtained 150-by-512 matrix\n",
      "Speed: 0.0319 sec/batch\n",
      "Computing distance matrix with metric=euclidean ...\n",
      "Computing CMC and mAP ...\n",
      "** Results **\n",
      "mAP: 22.0%\n",
      "CMC curve\n",
      "Rank-1  : 14.7%\n",
      "Rank-5  : 26.7%\n",
      "Rank-10 : 32.7%\n",
      "Rank-20 : 42.0%\n"
     ]
    }
   ],
   "source": [
    "# COmpile model\n",
    "engine = torchreid.engine.VideoSoftmaxEngine(\n",
    "    datamanager, model, optimizer, scheduler=scheduler,\n",
    "    pooling_method='avg'\n",
    ")\n",
    "\n",
    "engine.run(\n",
    "    max_epoch=60,\n",
    "    save_dir='log/oxnet_ilidsvid',\n",
    "    print_freq=10,\n",
    "    test_only=True,\n",
    "#     visrank = True, # visualize rank result\n",
    "#     visrank_topk = 5 # image to save\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652d4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
